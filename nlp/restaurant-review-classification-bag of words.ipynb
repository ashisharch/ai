{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars  sentiment\n",
       "0  Total bill for this horrible service? Over $8G...    1.0          0\n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...    5.0          1\n",
       "2  I have to say that this office really has it t...    5.0          1\n",
       "3  Went in for a lunch. Steak sandwich was delici...    5.0          1\n",
       "4  Today was my second out of three sessions I ha...    1.0          0"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.util import minibatch\n",
    "\n",
    "\n",
    "# Load in the data from JSON file\n",
    "data = pd.read_csv('yelp_ratings.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data & create training / validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"Some of the best sushi I've ever had....and I come from the East Coast.  Unreal toro, have some of it's available.\", {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), (\"One of the best burgers I've ever had and very well priced. I got the tortilla burger and is was delicious especially with there tortilla soup!\", {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), ('Review by a vegetarian family with two young kids. \\n\\nSeveral reviews have lamented the small number of vegetarian options on the menu and, while it is true that there are far more options for meat eaters and there is unfortunately no vegetarian noodle soup option, once you get over these 2 facts this is an excellent place for vegetarians.', {'cats': {'POSITIVE': True, 'NEGATIVE': False}})]\n"
     ]
    }
   ],
   "source": [
    "def load_data(csv_file, split=0.9):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Shuffle data\n",
    "    file_data = data.sample(frac=1, random_state=7)\n",
    "    #print(train_data)\n",
    "    \n",
    "    texts = file_data.text.values #verbatim text of emails\n",
    "    \n",
    "    labels = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} \n",
    "                for y in file_data.sentiment.values]\n",
    "    \n",
    "    split = int(len(file_data) * split) #num of samples to take for training\n",
    "    \n",
    "    train_labels = [{\"cats\": labels} for labels in labels[:split]] #take samples from end of list\n",
    "    val_labels = [{\"cats\": labels} for labels in labels[split:]] #take samples from beginning of list\n",
    "    #print(train_labels) - this contains the labels dictionary for each review with both True and False.\n",
    "    \n",
    "    return texts[:split], train_labels, texts[split:], val_labels\n",
    "\n",
    "#Load data and split into text and labels\n",
    "train_texts, train_labels, val_texts, val_labels = load_data('yelp_ratings.csv')\n",
    "\n",
    "#Create training data for model by combining training text and labels\n",
    "train_data = list(zip(train_texts, train_labels))\n",
    "\n",
    "print(train_data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty model\n",
    "nlp_model = spacy.blank('en')\n",
    "\n",
    "# Create the TextCategorizer with exclusive classes and \"bow\" i.e \"bag of words\" architecture\n",
    "textcat = nlp_model.create_pipe(\n",
    "              \"textcat\",\n",
    "              config={\n",
    "                \"exclusive_classes\": True,\n",
    "                \"architecture\": \"bow\"})\n",
    "\n",
    "# Add the TextCategorizer to the empty model\n",
    "nlp_model.add_pipe(textcat)\n",
    "\n",
    "# Add labels to text categorizer\n",
    "textcat.add_label(\"NEGATIVE\")\n",
    "textcat.add_label(\"POSITIVE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training function of TextCategorizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#Note: the training cannot begin without first calling begin_training()\n",
    "def train_model(model, train_data, optimizer):\n",
    "    model_loss = {}\n",
    "    random.seed(1)\n",
    "    random.shuffle(train_data)\n",
    "    \n",
    "    batches = minibatch(train_data, size=8)\n",
    "    for batch in batches:\n",
    "        # train_data is a list of tuples [(text0, label0), (text1, label1), ...]\n",
    "        # Split batch into texts and labels\n",
    "        texts, labels = zip(*batch)\n",
    "        \n",
    "        # Update model with texts and labels\n",
    "        model.update(texts, labels, sgd=optimizer, losses=model_loss)\n",
    "    \n",
    "    return model_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the training of model with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'textcat': 0.1062515708617866}\n",
      "0.1062515708617866\n"
     ]
    }
   ],
   "source": [
    "# Fix seed for reproducibility\n",
    "spacy.util.fix_random_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "losses = {}\n",
    "optimizer = nlp_model.begin_training()\n",
    "\n",
    "# Send all training data thru the model to train it. The epoch controls the interations of training \n",
    "# each iteration returns the losses for that iteration. Over multiple iterations, hopefully the losses converge near 0\n",
    "\n",
    "losses = train_model(nlp_model, train_data[:100], optimizer)\n",
    "print(losses)\n",
    "print(losses['textcat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the prediction of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NEGATIVE': 0.5063446760177612, 'POSITIVE': 0.4936552941799164}\n"
     ]
    }
   ],
   "source": [
    "#Test the prediction process on the trained model\n",
    "text = \"this is a bad restaurant it sucks\"\n",
    "doc = nlp_model(text)\n",
    "\n",
    "#.cats attribute of a Doc maps a label to a score for categories applied to the document. \n",
    "#The label is a string and the score should be a float.\n",
    "print(doc.cats) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(nlp, val_texts): \n",
    "    # Use the model's tokenizer to get a list of docs from the list of validation text\n",
    "    docs = [nlp.tokenizer(text) for text in val_texts]\n",
    "    #for doc in docs:\n",
    "    #    for token in doc:\n",
    "    #        print(f\"{token.text} \\t\\t\\t {token.lemma_} \\t\\t\\t {token.is_stop}\")\n",
    "    \n",
    "    # Use textcat to get the scores for each doc\n",
    "    textcat = nlp.get_pipe('textcat')\n",
    "    scores, tensors_not_used = textcat.predict(docs)\n",
    "    \n",
    "    #print(\"from predict->\", scores) #ndarray - a numberic score for each category in the categorizer i.e Negative , Positive\n",
    "    \n",
    "    # From the scores, find the class with the highest score/probability\n",
    "    predicted_class = scores.argmax(axis=1) #argmax with axis=1 gives the index of the highest value in each row\n",
    "    #print([textcat.labels[label] for label in predicted_class])\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "#Invoke prediction\n",
    "#print(val_texts[:2])\n",
    "#predict(nlp_model, val_texts[:2])\n",
    "\n",
    "#print(val_labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE == This magic show was the best one I've ever seen, very funny and great magic!!! We sat in the third row center and couldn't figure out any of the tricks, how does he do it? My sons (8 & 10) absolutely loved the show. My 10 year old volunteered to help on stage, he was super excited and as an extra bonus got a magic kit as a thank you at the end. We will definetely come back to this show, it's perfect family entertainment, loved every second of it!!!\n",
      "POSITIVE == There are a lot of good food places in Las Vegas, it's just a little bit harder to find them in the North side! It's located inside a gas station, but area seems to look just fine in my opinion! I may say a lot of people are nice in my reviews, but really, the owner is welcoming to his customers and if there are any adjustments that needs to be made he is more than willing to fix it or make up for it somehow. The price here is also great! I have only tried the tacos, but they're all really good with the sauce! You have to get the hot sauce! :)\n"
     ]
    }
   ],
   "source": [
    "texts = val_texts[:2]\n",
    "predictions = predict(nlp_model, texts)\n",
    "\n",
    "for p,t in zip(predictions, texts):\n",
    "    print(f\"{textcat.labels[p]} == {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Evaluation function to evaluate model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(model, texts, labels):\n",
    "    \"\"\" Returns the accuracy of a TextCategorizer model. \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        model: ScaPy model with a TextCategorizer\n",
    "        texts: Text samples, from load_data function\n",
    "        labels: True labels, from load_data function\n",
    "    \n",
    "    \"\"\"\n",
    "    # Get predictions from textcat model (using your predict method)\n",
    "    predicted_class = predict(model, texts)\n",
    "    #print(\"predicted_class\", predicted_class)\n",
    "    \n",
    "    # From labels, get the true class as a list of integers (POSITIVE -> 1, NEGATIVE -> 0)\n",
    "    true_class = [int(cat['cats']['POSITIVE']==True) for cat in labels ]\n",
    "    #print(\"true class=\", true_class)\n",
    "    \n",
    "    # A boolean or int array indicating correct predictions\n",
    "    correct_predictions = predicted_class == true_class\n",
    "    #print(\"correct_predictions\", correct_predictions)\n",
    "    \n",
    "    # The accuracy, number of correct predictions divided by all predictions\n",
    "    accuracy = np.sum(correct_predictions) / len(correct_predictions)\n",
    "    \n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "#Test evaluation function\n",
    "evaluate(nlp_model, val_texts[:5], val_labels[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: losses = {'textcat': 3.4813461700089476e-06}\n",
      "1: losses = {'textcat': 3.2784053198842145e-06}\n",
      "2: losses = {'textcat': 3.0675511841771197e-06}\n",
      "3: losses = {'textcat': 2.8848378301749023e-06}\n",
      "4: losses = {'textcat': 2.7267506208517034e-06}\n",
      "5: losses = {'textcat': 2.586872273724339e-06}\n",
      "6: losses = {'textcat': 2.4607064732506956e-06}\n",
      "7: losses = {'textcat': 2.3454110591458743e-06}\n",
      "8: losses = {'textcat': 2.239060001407722e-06}\n",
      "9: losses = {'textcat': 2.1403423178245617e-06}\n",
      "Accuracy = 0.6\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "train_count = 100\n",
    "val_count = 10\n",
    "\n",
    "#First lets train the model on a larger training set and multiple iterations\n",
    "for i in range(epoch):\n",
    "    losses = train_model(nlp_model, train_data[:train_count], optimizer)\n",
    "    print(f\"{i}: losses = {losses}\")\n",
    "    \n",
    "#Now, lets evaluate how the model does on the validation texts\n",
    "accuracy = evaluate(nlp_model, val_texts[:val_count], val_labels[:val_count])\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "\n",
    "#nlp_model.to_disk(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NEGATIVE': 0.40553024411201477, 'POSITIVE': 0.5944697856903076}\n"
     ]
    }
   ],
   "source": [
    "#Test the prediction process on the trained model\n",
    "text = \"The food was disgusting and lacked flavor\"\n",
    "doc = nlp_model(text)\n",
    "\n",
    "#.cats attribute of a Doc maps a label to a score for categories applied to the document. \n",
    "#The label is a string and the score should be a float.\n",
    "print(doc.cats) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
