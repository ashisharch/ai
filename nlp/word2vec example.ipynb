{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Need to load the large model to get the vectors\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing - create word vectors using the spacy large vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 300)\n",
      "These \t\t\t these \t\t\t True\n",
      "vectors \t\t\t vector \t\t\t False\n",
      "are \t\t\t be \t\t\t True\n",
      "great \t\t\t great \t\t\t False\n"
     ]
    }
   ],
   "source": [
    "#Word level vectors\n",
    "text = \"These vectors are great\"\n",
    "doc = nlp(text)\n",
    "\n",
    "with nlp.disable_pipes():\n",
    "    vectors = np.array([token.vector for token in doc])\n",
    "\n",
    "print(vectors.shape)\n",
    "for token in doc:\n",
    "    print(f\"{token.text} \\t\\t\\t {token.lemma_} \\t\\t\\t {token.is_stop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc level vectors\n",
    "review_comments_file = [\"first sentence\", \"second sentence\"]\n",
    "review_sentiment = [0,1]\n",
    "\n",
    "with nlp.disable_pipes():\n",
    "    v2 = np.array([nlp(row).vector for row in review_comments_file])\n",
    "    #print(np.array([nlp(row).vector for row in file]))\n",
    "#print(v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the yelp ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars  sentiment\n",
       "0  Total bill for this horrible service? Over $8G...    1.0          0\n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...    5.0          1\n",
       "2  I have to say that this office really has it t...    5.0          1\n",
       "3  Went in for a lunch. Steak sandwich was delici...    5.0          1\n",
       "4  Today was my second out of three sessions I ha...    1.0          0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the data from JSON file\n",
    "data = pd.read_csv('yelp_ratings.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 300)\n"
     ]
    }
   ],
   "source": [
    "#Test the vector creation from actual data\n",
    "\n",
    "review_verbatim = data.text[:5]\n",
    "review_sentiment = data.sentiment[:5]\n",
    "\n",
    "#Get the word vectors for the doc into an array\n",
    "with nlp.disable_pipes():\n",
    "    review_vectors = np.array([nlp(row).vector for row in review_verbatim])\n",
    "\n",
    "print(review_vectors.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training / test data created\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "#Since creating vectors on a dataset of 44k rows will take time, this task was done offline and stored in a file\n",
    "# Loading all document vectors from file into an array\n",
    "review_vectors = np.load('review_vectors.npy')\n",
    "\n",
    "#Use the word vectors to create train/test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(review_vectors, data.sentiment, test_size=0.1, random_state=1)\n",
    "\n",
    "print(\"training / test data created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a few different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 93.847%\n",
      "--- 2.8593268394470215 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "start_time = time.time()\n",
    "# Create the LinearSVC model\n",
    "mSVC = LinearSVC(random_state=1, dual=False)\n",
    "# Fit the model on training data\n",
    "mSVC.fit(X_train, y_train)\n",
    "\n",
    "# Uncomment and run to see model accuracy\n",
    "print(f'Model test accuracy: {mSVC.score(X_test, y_test)*100:.3f}%')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 86.998%\n",
      "--- 78.88813304901123 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "mKNN = KNeighborsClassifier(n_neighbors=5)\n",
    "mKNN.fit(X_train, y_train)\n",
    "print(f'Model test accuracy: {mKNN.score(X_test, y_test)*100:.3f}%')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8120368291039749\n",
      "[[ 718  408]\n",
      " [ 429 2898]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63      1126\n",
      "           1       0.88      0.87      0.87      3327\n",
      "\n",
      "    accuracy                           0.81      4453\n",
      "   macro avg       0.75      0.75      0.75      4453\n",
      "weighted avg       0.81      0.81      0.81      4453\n",
      "\n",
      "--- 22.56112003326416 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "mDTC = DecisionTreeClassifier()\n",
    "mDTC.fit(X_train, y_train)\n",
    "y_pred = mDTC.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC model accuracy for good: 100.0%\n",
      "SVC model accuracy for bad: 100.0%\n",
      "KNN Model test accuracy for good: 0.0%\n",
      "KNN Model test accuracy for bad: 0.0%\n",
      "DTC model accuracy for good: 0.0%\n",
      "DTC model accuracy for bad: 0.0%\n"
     ]
    }
   ],
   "source": [
    "good_review = \"\"\"I like the food, and i Like the people..\"\"\"\n",
    "\n",
    "bad_review = \"\"\"this is not a good restaurant. No good food, location was just ok.\"\"\"\n",
    "\n",
    "#Create word vectors for the reviews and reshape since there is only 1 sample\n",
    "my_good_review = (nlp(good_review).vector).reshape(1,-1)\n",
    "my_good_label = [1]\n",
    "\n",
    "my_bad_review = (nlp(bad_review).vector).reshape(1,-1)\n",
    "my_bad_label = [0]\n",
    "\n",
    "print(f'SVC model accuracy for good: {mSVC.score(my_good_review, my_good_label)*100}%')\n",
    "print(f'SVC model accuracy for bad: {mSVC.score(my_bad_review, my_bad_label)*100}%')\n",
    "\n",
    "print(f'KNN Model test accuracy for good: {mKNN.score(my_good_review, my_good_label)*100}%')\n",
    "print(f'KNN Model test accuracy for bad: {mKNN.score(my_bad_review, my_bad_label)*100:.1f}%')\n",
    "\n",
    "print(f\"DTC model accuracy for good: {metrics.accuracy_score(my_good_label, mDTC.predict(my_good_review))*100:.1f}%\")\n",
    "print(f\"DTC model accuracy for bad: {metrics.accuracy_score(my_bad_label, mDTC.predict(my_bad_review))*100:.1f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between a & b is 77.1%\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b)/np.sqrt(a.dot(a)*b.dot(b))\n",
    "\n",
    "#Lets test similarity first\n",
    "a = nlp(\"I absolutely love this place. The 360 degree glass windows with the Yerba buena garden view, tea pots all around and\").vector\n",
    "b = nlp(\"The space is a dark hole\").vector\n",
    "print(f\"similarity between a & b is {cosine_similarity(a, b)*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity exercise (not model related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44530, 300)\n",
      "Most similar review == 59.152% -- After purchasing my final christmas gifts at the Urban Tea Merchant in Vancouver, I was surprised to hear about Teopia at the new outdoor mall at Don Mills and Lawrence when I went back home to Toronto for Christmas.\n",
      "Across from the outdoor skating rink and perfect to sit by the ledge to people watch, the location was prime for tea connesieurs... or people who are just freezing cold in need of a drinK!\n",
      "Like any gourmet tea shop, there were large tins of tea leaves on the walls, and although the tea menu seemed interesting enough, you can get any specialty tea as your drink. We didn't know what to get... so the lady suggested the Goji Berries... it smelled so succulent and juicy... instantly SOLD! I got it into a tea latte and watched the tea steep while the milk was steamed, and surprisingly, with the click of a button, all the water from the tea can be instantly drained into the cup (see photo).. very fascinating!\n",
      "\n",
      "The tea was aromatic and tasty, not over powering. The price was also very reasonable and I recommend everyone to get a taste of this place :)\n"
     ]
    }
   ],
   "source": [
    "#Now lets find similarity of 1 review to other reviews in file. \n",
    "# This exercise does not rely on the trained models above, just on the vectors defined above.\n",
    "target_review = \"\"\"I absolutely love this place. The 360 degree glass windows with the \n",
    "Yerba buena garden view, tea pots all around and the smell of fresh tea everywhere \n",
    "transports you to what feels like a different zen zone within the city. I know \n",
    "the price is slightly more compared to the normal American size, however the food \n",
    "is very wholesome, the tea selection is incredible and I know service can be hit \n",
    "or miss often but it was on point during our most recent visit. Definitely recommend!\n",
    "I would especially recommend the butternut squash gyoza.\"\"\"\n",
    "\n",
    "#get the word vector for the target review\n",
    "review_vec = nlp(target_review).vector\n",
    "\n",
    "## Center the document vectors\n",
    "#To calculate similarity of this review ot other reviews, we need to make sure we are comparing to reviews in this file\n",
    "#In order to make sure we are comparing reviews to other reviews within the file, \n",
    "# we \"center\" the reviews, by finding the mean of all reviews in the file\n",
    "# Calculate the mean for the document vectors, should have shape (300,)\n",
    "vec_mean = review_vectors.mean(axis=0)\n",
    "# Subtract the mean from the vectors\n",
    "centered = review_vectors - vec_mean\n",
    "print(centered.shape)\n",
    "\n",
    "\n",
    "# Calculate similarities for each document in the dataset\n",
    "# Make sure to subtract the mean from the review vector\n",
    "sims = np.array([cosine_similarity(review_vec-vec_mean, v) for v in centered])\n",
    "\n",
    "# Get the index for the most similar document\n",
    "most_similar = sims.argmax()\n",
    "\n",
    "#Lets see the text for most similar review and check for ourselves\n",
    "print(f\"Most similar review == {sims[sims.argmax()]*100:.3f}% -- {data.iloc[most_similar].text}\")\n",
    "\n",
    "#print(sims)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'wv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-fea61fadbd57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtsne_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-169-fea61fadbd57>\u001b[0m in \u001b[0;36mtsne_plot\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'wv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.vocab:\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()\n",
    "    \n",
    "tsne_plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
