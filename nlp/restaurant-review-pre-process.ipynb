{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "how is it going i'll"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "docs = nlp.tokenizer(\"how is it going i'll\")\n",
    "\n",
    "x = [token for token in docs]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>lDJIaF4eYRF4F7g6Zb9euw</td>\n",
       "      <td>lb0QUR5bc4O-Am4hNq9ZGg</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I used to work food service and my manager at ...</td>\n",
       "      <td>2013-01-27 17:54:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>vvIzf3pr8lTqE_AOsxmgaA</td>\n",
       "      <td>MAmijW4ooUzujkufYYLMeQ</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We have been trying Eggplant sandwiches all ov...</td>\n",
       "      <td>2015-04-15 04:50:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>UF-JqzMczZ8vvp_4tPK3bQ</td>\n",
       "      <td>slfi6gf_qEYTXy90Sw93sg</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazing Steak and Cheese... Better than any Ph...</td>\n",
       "      <td>2011-03-20 00:57:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>geUJGrKhXynxDC2uvERsLw</td>\n",
       "      <td>N_-UepOzAsuDQwOUtfRFGw</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Although I have been going to DeFalco's for ye...</td>\n",
       "      <td>2018-07-17 01:48:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>aPctXPeZW3kDq36TRm-CqA</td>\n",
       "      <td>139hD7gkZVzSvSzDPwhNNw</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Highs: Ambience, value, pizza and deserts. Thi...</td>\n",
       "      <td>2018-01-21 10:52:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   review_id                 user_id             business_id  \\\n",
       "109   lDJIaF4eYRF4F7g6Zb9euw  lb0QUR5bc4O-Am4hNq9ZGg  r5PLDU-4mSbde5XekTXSCA   \n",
       "1013  vvIzf3pr8lTqE_AOsxmgaA  MAmijW4ooUzujkufYYLMeQ  r5PLDU-4mSbde5XekTXSCA   \n",
       "1204  UF-JqzMczZ8vvp_4tPK3bQ  slfi6gf_qEYTXy90Sw93sg  r5PLDU-4mSbde5XekTXSCA   \n",
       "1251  geUJGrKhXynxDC2uvERsLw  N_-UepOzAsuDQwOUtfRFGw  r5PLDU-4mSbde5XekTXSCA   \n",
       "1354  aPctXPeZW3kDq36TRm-CqA  139hD7gkZVzSvSzDPwhNNw  r5PLDU-4mSbde5XekTXSCA   \n",
       "\n",
       "      stars  useful  funny  cool  \\\n",
       "109       4       2      0     0   \n",
       "1013      4       0      0     0   \n",
       "1204      5       1      0     0   \n",
       "1251      1       0      0     0   \n",
       "1354      2       0      0     0   \n",
       "\n",
       "                                                   text                date  \n",
       "109   I used to work food service and my manager at ... 2013-01-27 17:54:54  \n",
       "1013  We have been trying Eggplant sandwiches all ov... 2015-04-15 04:50:56  \n",
       "1204  Amazing Steak and Cheese... Better than any Ph... 2011-03-20 00:57:45  \n",
       "1251  Although I have been going to DeFalco's for ye... 2018-07-17 01:48:23  \n",
       "1354  Highs: Ambience, value, pizza and deserts. Thi... 2018-01-21 10:52:58  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the data from JSON file\n",
    "data = pd.read_json('restaurant.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = [\"Cheese Steak\", \"Cheesesteak\", \"Steak and Cheese\", \"Italian Combo\", \"Tiramisu\", \"Cannoli\",\n",
    "        \"Chicken Salad\", \"Chicken Spinach Salad\", \"Meatball\", \"Pizza\", \"Pizzas\", \"Spaghetti\",\n",
    "        \"Bruchetta\", \"Eggplant\", \"Italian Beef\", \"Purista\", \"Pasta\", \"Calzones\",  \"Calzone\",\n",
    "        \"Italian Sausage\", \"Chicken Cutlet\", \"Chicken Parm\", \"Chicken Parmesan\", \"Gnocchi\",\n",
    "        \"Chicken Pesto\", \"Turkey Sandwich\", \"Turkey Breast\", \"Ziti\", \"Portobello\", \"Reuben\",\n",
    "        \"Mozzarella Caprese\",  \"Corned Beef\", \"Garlic Bread\", \"Pastrami\", \"Roast Beef\",\n",
    "        \"Tuna Salad\", \"Lasagna\", \"Artichoke Salad\", \"Fettuccini Alfredo\", \"Chicken Parmigiana\",\n",
    "        \"Grilled Veggie\", \"Grilled Veggies\", \"Grilled Vegetable\", \"Mac and Cheese\", \"Macaroni\",  \n",
    "         \"Prosciutto\", \"Salami\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We have been trying Eggplant sandwiches all over the valley because my day loves eggplant.  Delfaco's sandwich on the Italian Hoagie had way way too much bread more bread than eggplant.  The eggplant by itself was very tasty, but get it without so much bread, you will thank me later.  We will be back to try something else.  I went at 11 am on a Saturday morning and still waited over 30 minutes for a take out order.  It is a very crammed space, a little Italian deli in between a Italian grocery store.  The prices for the Italian pastas and cheese are a bit over priced.  The espresso is nicely priced at $1.40 for a single shot.\""
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_of_review_to_test_on = 1\n",
    "text_to_test_on = data.text.iloc[index_of_review_to_test_on]\n",
    "\n",
    "text_to_test_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We \t\t\t -PRON- \t\t\t True\n",
      "have \t\t\t have \t\t\t True\n",
      "been \t\t\t be \t\t\t True\n",
      "trying \t\t\t try \t\t\t False\n",
      "Eggplant \t\t\t eggplant \t\t\t False\n",
      "sandwiches \t\t\t sandwich \t\t\t False\n",
      "all \t\t\t all \t\t\t True\n",
      "over \t\t\t over \t\t\t True\n",
      "the \t\t\t the \t\t\t True\n",
      "valley \t\t\t valley \t\t\t False\n",
      "because \t\t\t because \t\t\t True\n",
      "my \t\t\t -PRON- \t\t\t True\n",
      "day \t\t\t day \t\t\t False\n",
      "loves \t\t\t love \t\t\t False\n",
      "eggplant \t\t\t eggplant \t\t\t False\n",
      ". \t\t\t . \t\t\t False\n",
      "  \t\t\t   \t\t\t False\n",
      "Delfaco \t\t\t Delfaco \t\t\t False\n",
      "'s \t\t\t 's \t\t\t True\n",
      "sandwich \t\t\t sandwich \t\t\t False\n",
      "on \t\t\t on \t\t\t True\n",
      "the \t\t\t the \t\t\t True\n",
      "Italian \t\t\t Italian \t\t\t False\n",
      "Hoagie \t\t\t Hoagie \t\t\t False\n",
      "had \t\t\t have \t\t\t True\n",
      "way \t\t\t way \t\t\t False\n",
      "way \t\t\t way \t\t\t False\n",
      "too \t\t\t too \t\t\t True\n",
      "much \t\t\t much \t\t\t True\n",
      "bread \t\t\t bread \t\t\t False\n",
      "more \t\t\t more \t\t\t True\n",
      "bread \t\t\t bread \t\t\t False\n",
      "than \t\t\t than \t\t\t True\n",
      "eggplant \t\t\t eggplant \t\t\t False\n",
      ". \t\t\t . \t\t\t False\n",
      "  \t\t\t   \t\t\t False\n",
      "The \t\t\t the \t\t\t True\n",
      "eggplant \t\t\t eggplant \t\t\t False\n",
      "by \t\t\t by \t\t\t True\n",
      "itself \t\t\t -PRON- \t\t\t True\n",
      "was \t\t\t be \t\t\t True\n",
      "very \t\t\t very \t\t\t True\n",
      "tasty \t\t\t tasty \t\t\t False\n",
      ", \t\t\t , \t\t\t False\n",
      "but \t\t\t but \t\t\t True\n",
      "get \t\t\t get \t\t\t True\n",
      "it \t\t\t -PRON- \t\t\t True\n",
      "without \t\t\t without \t\t\t True\n",
      "so \t\t\t so \t\t\t True\n",
      "much \t\t\t much \t\t\t True\n",
      "bread \t\t\t bread \t\t\t False\n",
      ", \t\t\t , \t\t\t False\n",
      "you \t\t\t -PRON- \t\t\t True\n",
      "will \t\t\t will \t\t\t True\n",
      "thank \t\t\t thank \t\t\t False\n",
      "me \t\t\t -PRON- \t\t\t True\n",
      "later \t\t\t later \t\t\t False\n",
      ". \t\t\t . \t\t\t False\n",
      "  \t\t\t   \t\t\t False\n",
      "We \t\t\t -PRON- \t\t\t True\n",
      "will \t\t\t will \t\t\t True\n",
      "be \t\t\t be \t\t\t True\n",
      "back \t\t\t back \t\t\t True\n",
      "to \t\t\t to \t\t\t True\n",
      "try \t\t\t try \t\t\t False\n",
      "something \t\t\t something \t\t\t True\n",
      "else \t\t\t else \t\t\t True\n",
      ". \t\t\t . \t\t\t False\n",
      "  \t\t\t   \t\t\t False\n",
      "I \t\t\t -PRON- \t\t\t True\n",
      "went \t\t\t go \t\t\t False\n",
      "at \t\t\t at \t\t\t True\n",
      "11 \t\t\t 11 \t\t\t False\n",
      "am \t\t\t am \t\t\t True\n",
      "on \t\t\t on \t\t\t True\n",
      "a \t\t\t a \t\t\t True\n",
      "Saturday \t\t\t Saturday \t\t\t False\n",
      "morning \t\t\t morning \t\t\t False\n",
      "and \t\t\t and \t\t\t True\n",
      "still \t\t\t still \t\t\t True\n",
      "waited \t\t\t wait \t\t\t False\n",
      "over \t\t\t over \t\t\t True\n",
      "30 \t\t\t 30 \t\t\t False\n",
      "minutes \t\t\t minute \t\t\t False\n",
      "for \t\t\t for \t\t\t True\n",
      "a \t\t\t a \t\t\t True\n",
      "take \t\t\t take \t\t\t True\n",
      "out \t\t\t out \t\t\t True\n",
      "order \t\t\t order \t\t\t False\n",
      ". \t\t\t . \t\t\t False\n",
      "  \t\t\t   \t\t\t False\n",
      "It \t\t\t -PRON- \t\t\t True\n",
      "is \t\t\t be \t\t\t True\n",
      "a \t\t\t a \t\t\t True\n",
      "very \t\t\t very \t\t\t True\n",
      "crammed \t\t\t crammed \t\t\t False\n",
      "space \t\t\t space \t\t\t False\n",
      ", \t\t\t , \t\t\t False\n",
      "a \t\t\t a \t\t\t True\n",
      "little \t\t\t little \t\t\t False\n",
      "Italian \t\t\t italian \t\t\t False\n",
      "deli \t\t\t deli \t\t\t False\n",
      "in \t\t\t in \t\t\t True\n",
      "between \t\t\t between \t\t\t True\n",
      "a \t\t\t a \t\t\t True\n",
      "Italian \t\t\t italian \t\t\t False\n",
      "grocery \t\t\t grocery \t\t\t False\n",
      "store \t\t\t store \t\t\t False\n",
      ". \t\t\t . \t\t\t False\n",
      "  \t\t\t   \t\t\t False\n",
      "The \t\t\t the \t\t\t True\n",
      "prices \t\t\t price \t\t\t False\n",
      "for \t\t\t for \t\t\t True\n",
      "the \t\t\t the \t\t\t True\n",
      "Italian \t\t\t italian \t\t\t False\n",
      "pastas \t\t\t pasta \t\t\t False\n",
      "and \t\t\t and \t\t\t True\n",
      "cheese \t\t\t cheese \t\t\t False\n",
      "are \t\t\t be \t\t\t True\n",
      "a \t\t\t a \t\t\t True\n",
      "bit \t\t\t bit \t\t\t False\n",
      "over \t\t\t over \t\t\t True\n",
      "priced \t\t\t price \t\t\t False\n",
      ". \t\t\t . \t\t\t False\n",
      "  \t\t\t   \t\t\t False\n",
      "The \t\t\t the \t\t\t True\n",
      "espresso \t\t\t espresso \t\t\t False\n",
      "is \t\t\t be \t\t\t True\n",
      "nicely \t\t\t nicely \t\t\t False\n",
      "priced \t\t\t price \t\t\t False\n",
      "at \t\t\t at \t\t\t True\n",
      "$ \t\t\t $ \t\t\t False\n",
      "1.40 \t\t\t 1.40 \t\t\t False\n",
      "for \t\t\t for \t\t\t True\n",
      "a \t\t\t a \t\t\t True\n",
      "single \t\t\t single \t\t\t False\n",
      "shot \t\t\t shot \t\t\t False\n",
      ". \t\t\t . \t\t\t False\n"
     ]
    }
   ],
   "source": [
    "# Create the tokenized version of text_to_test_on\n",
    "review_doc = nlp(text_to_test_on)\n",
    "for token in review_doc:\n",
    "    print(f\"{token.text} \\t\\t\\t {token.lemma_} \\t\\t\\t {token.is_stop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PhraseMatcher object. The tokenizer is the first argument. Use attr = 'LOWER' to make consistent capitalization\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "\n",
    "# Create a list of tokens for each item in the menu. The list contains a collection of \"doc\" objects\n",
    "menu_tokens_list = [nlp(item) for item in menu]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(533989841420491665, 4, 5), (533989841420491665, 14, 15), (533989841420491665, 33, 34), (533989841420491665, 37, 38)]\n"
     ]
    }
   ],
   "source": [
    "matcher.add(\"MenuItems\", menu_tokens_list)\n",
    "\n",
    "items_in_review = matcher(review_doc) #Get the list of menu items that are in the review\n",
    "print(items_in_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token-> 4 Eggplant\n",
      "token-> 14 eggplant\n",
      "token-> 33 eggplant\n",
      "token-> 37 eggplant\n",
      "533989841420491665 / 4 / 5\n",
      "533989841420491665 / 14 / 15\n",
      "533989841420491665 / 33 / 34\n",
      "533989841420491665 / 37 / 38\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in items_in_review:\n",
    "    print(\"token->\", start, review_doc[start:end])\n",
    "    \n",
    "for match in items_in_review:\n",
    "    print(match[0], \"/\", match[1], \"/\", match[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will create a dictionary of all items and their ratings which can be used for modeling\n",
    "from collections import defaultdict\n",
    "\n",
    "item_ratings = defaultdict(list) #dictionary of item: rating list e.g. {'eggplant' : [1,2,4,5,5,4,3,3]}\n",
    "\n",
    "for idx, review in data.iterrows():\n",
    "    #print(idx, review.stars)\n",
    "    doc = nlp(review.text) #convert user review text into an NLP doc\n",
    "    items_in_review = matcher(doc) #find all menu items referenced in user review\n",
    "    \n",
    "    #doc[match1:match2] gets the name of menu item\n",
    "    found_items = set([doc[match[1]:match[2]].lower_ for match in items_in_review])\n",
    "    #print(found_items)\n",
    "\n",
    "    for item in found_items:\n",
    "        item_ratings[item].append(review.stars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chicken parmigiana': 4.470588235294118, 'eggplant': 4.159420289855072, 'pizza': 4.339622641509434, 'steak and cheese': 4.888888888888889, 'meatball': 4.1796875, 'cannoli': 4.388888888888889, 'pasta': 4.407766990291262, 'purista': 4.666666666666667, 'prosciutto': 4.68, 'cheese steak': 4.447368421052632, 'cheesesteak': 4.484536082474227, 'calzone': 4.444444444444445, 'italian combo': 4.0476190476190474, 'tiramisu': 4.238095238095238, 'chicken spinach salad': 4.5, 'italian beef': 3.92, 'salami': 4.25, 'chicken parm': 4.22, 'ziti': 4.380952380952381, 'chicken cutlet': 3.4, 'turkey sandwich': 3.8, 'tuna salad': 4.0, 'chicken pesto': 4.555555555555555, 'artichoke salad': 5.0, 'lasagna': 4.4576271186440675, 'fettuccini alfredo': 5.0, 'pizzas': 4.375, 'turkey breast': 5.0, 'calzones': 4.542857142857143, 'grilled veggie': 4.5, 'mac and cheese': 4.454545454545454, 'garlic bread': 4.128205128205129, 'spaghetti': 3.888888888888889, 'italian sausage': 4.30188679245283, 'portobello': 4.5, 'pastrami': 4.444444444444445, 'reuben': 4.75, 'gnocchi': 4.486486486486487, 'chicken parmesan': 4.2631578947368425, 'macaroni': 4.0, 'chicken salad': 4.6, 'roast beef': 4.142857142857143, 'corned beef': 5.0}\n"
     ]
    }
   ],
   "source": [
    "mean_ratings = {} #dictionary to store mean values - menu_item : mean_rating\n",
    "\n",
    "#for item in item_ratings:\n",
    "#    mean_ratings[item] = sum(item_ratings[item]) / len(item_ratings[item])\n",
    "\n",
    "#list comprehension for-loop is used to simplify the code, but works exactly as 2 lines above.\n",
    "mean_ratings = {item:sum(item_ratings[item]) / len(item_ratings[item]) for item in item_ratings}\n",
    "    \n",
    "print(mean_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chicken cutlet\n",
      "3.4\n"
     ]
    }
   ],
   "source": [
    "worst_item = sorted(mean_ratings, key=mean_ratings.get)[0]\n",
    "\n",
    "print(worst_item)\n",
    "print(mean_ratings[worst_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ggg pizza / 265\n",
      "ggg pasta / 206\n",
      "ggg meatball / 128\n",
      "ggg cheesesteak / 97\n",
      "ggg cheese steak / 76\n",
      "ggg cannoli / 72\n",
      "ggg calzone / 72\n",
      "ggg eggplant / 69\n",
      "ggg purista / 63\n",
      "ggg lasagna / 59\n",
      "ggg italian sausage / 53\n",
      "ggg prosciutto / 50\n",
      "ggg chicken parm / 50\n",
      "ggg garlic bread / 39\n",
      "ggg gnocchi / 37\n",
      "ggg spaghetti / 36\n",
      "ggg calzones / 35\n",
      "ggg pizzas / 32\n",
      "ggg salami / 28\n",
      "ggg chicken pesto / 27\n",
      "ggg italian beef / 25\n",
      "ggg italian combo / 21\n",
      "ggg tiramisu / 21\n",
      "ggg ziti / 21\n",
      "ggg chicken parmesan / 19\n",
      "ggg chicken parmigiana / 17\n",
      "ggg portobello / 14\n",
      "ggg mac and cheese / 11\n",
      "ggg chicken cutlet / 10\n",
      "ggg steak and cheese / 9\n",
      "ggg pastrami / 9\n",
      "ggg roast beef / 7\n",
      "ggg fettuccini alfredo / 6\n",
      "ggg grilled veggie / 6\n",
      "ggg turkey sandwich / 5\n",
      "ggg tuna salad / 5\n",
      "ggg artichoke salad / 5\n",
      "ggg macaroni / 5\n",
      "ggg chicken salad / 5\n",
      "ggg reuben / 4\n",
      "ggg chicken spinach salad / 2\n",
      "ggg corned beef / 2\n",
      "ggg turkey breast / 1\n"
     ]
    }
   ],
   "source": [
    "#Count of ratings per menu item\n",
    "freq = {item: len(ratings) for item, ratings in item_ratings.items()}\n",
    "#print(freq)\n",
    "most_reviews = sorted(freq, key=freq.get, reverse=True)\n",
    "\n",
    "for item in most_reviews:\n",
    "    print(f\"ggg {item} / {freq[item]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
